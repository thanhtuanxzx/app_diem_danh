import * as faceapi from "face-api.js";
import { Canvas, Image, ImageData, loadImage } from "canvas";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";

// Cáº¥u hÃ¬nh Canvas cho Node.js
const __dirname = path.dirname(fileURLToPath(import.meta.url));
faceapi.env.monkeyPatch({ Canvas, Image, ImageData });

// Load model
const loadModels = async () => {
  const modelPath = path.join(__dirname, "../models");
  await faceapi.nets.ssdMobilenetv1.loadFromDisk(modelPath);
  await faceapi.nets.faceLandmark68Net.loadFromDisk(modelPath);
  await faceapi.nets.faceRecognitionNet.loadFromDisk(modelPath);
};

await loadModels();

const trainedDataPath = path.join(__dirname, "../trainedData.json");

// ðŸŸ¢ **HÃ m train dá»¯ liá»‡u**
// export const trainFaces = async (req, res) => {
//   try {
//     const datasetPath = path.join(__dirname, "../dataset");
//     const labels = fs.readdirSync(datasetPath);

//     const labeledFaceDescriptors = [];

//     for (const label of labels) {
//       const imagesPath = path.join(datasetPath, label);
//       const images = fs.readdirSync(imagesPath);

//       const descriptors = [];

//       for (const image of images) {
//         const imgPath = path.join(imagesPath, image);
//         const img = await loadImage(imgPath);

//         const detection = await faceapi
//           .detectSingleFace(img)
//           .withFaceLandmarks()
//           .withFaceDescriptor();

//         if (detection) descriptors.push(Array.from(detection.descriptor)); // ðŸŸ¢ Chuyá»ƒn thÃ nh máº£ng sá»‘
//       }

//       if (descriptors.length > 0) {
//         labeledFaceDescriptors.push({ label, descriptors });
//       }
//     }

//     fs.writeFileSync(trainedDataPath, JSON.stringify(labeledFaceDescriptors, null, 2));
//     res.json({ message: "âœ… Training hoÃ n táº¥t!", data: labeledFaceDescriptors });

//   } catch (error) {
//     console.error("âŒ Lá»—i training:", error);
//     res.status(500).json({ message: "âŒ Lá»—i server", error });
//   }
// };

export const trainFaces = async (req, res) => {
  try {
    if (!req.files || req.files.length === 0 || !req.body.label) {
      return res.status(400).json({ message: "âŒ Cáº§n cÃ³ áº£nh vÃ  nhÃ£n (label)!" });
    }

    const { label } = req.body; // ðŸ·ï¸ Láº¥y nhÃ£n cá»§a khuÃ´n máº·t
    let trainedFaces = [];

    // ðŸ“‚ **Äá»c dá»¯ liá»‡u Ä‘Ã£ train trÆ°á»›c Ä‘Ã³**
    if (fs.existsSync(trainedDataPath)) {
      trainedFaces = JSON.parse(fs.readFileSync(trainedDataPath));
    }

    // ðŸ” **TÃ¬m xem nhÃ£n Ä‘Ã£ tá»“n táº¡i chÆ°a**
    let existingPerson = trainedFaces.find((person) => person.label === label);

    if (!existingPerson) {
      existingPerson = { label, descriptors: [] };
      trainedFaces.push(existingPerson);
    }

    // ðŸ“¸ **Duyá»‡t qua tá»«ng áº£nh vÃ  trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng**
    for (const file of req.files) {
      console.log(`ðŸ–¼ï¸ Äang xá»­ lÃ½ áº£nh: ${file.originalname}`);

      const img = await loadImage(file.path);
      const detection = await faceapi
        .detectSingleFace(img)
        .withFaceLandmarks()
        .withFaceDescriptor();

      if (detection) {
        const descriptor = Array.from(detection.descriptor);
        existingPerson.descriptors.push(descriptor); // ðŸ”„ ThÃªm descriptor vÃ o danh sÃ¡ch
      }

      fs.unlinkSync(file.path); // ðŸ—‘ï¸ XÃ³a áº£nh sau khi train
    }

    // ðŸ’¾ **LÆ°u dá»¯ liá»‡u Ä‘Ã£ train**
    fs.writeFileSync(trainedDataPath, JSON.stringify(trainedFaces, null, 2));

    res.json({ message: "âœ… Training hoÃ n táº¥t!", label });

  } catch (error) {
    console.error("âŒ Lá»—i training:", error);
    res.status(500).json({ message: "âŒ Lá»—i server", error });
  }
};


// ðŸŸ¢ **HÃ m nháº­n diá»‡n khuÃ´n máº·t**
export const verifyFace = async (req, res) => {
  try {
    if (!req.file) return res.status(400).json({ message: "âŒ KhÃ´ng cÃ³ áº£nh táº£i lÃªn!" });

    console.log(`ðŸ“¸ áº¢nh táº£i lÃªn: ${req.file.path}`);
    const imgPath = path.join(__dirname, "../", req.file.path);
    const img = await loadImage(imgPath);

    const detection = await faceapi
      .detectSingleFace(img)
      .withFaceLandmarks()
      .withFaceDescriptor();

    if (!detection) return res.status(400).json({ message: "âŒ KhÃ´ng tÃ¬m tháº¥y khuÃ´n máº·t nÃ o!" });

    const uploadedDescriptor = Array.from(detection.descriptor); // ðŸŸ¢ Chuyá»ƒn thÃ nh máº£ng sá»‘

    // ðŸŸ¢ **Äá»c & chuáº©n hÃ³a dá»¯ liá»‡u Ä‘Ã£ train**
    if (!fs.existsSync(trainedDataPath)) {
      return res.status(500).json({ message: "âŒ ChÆ°a cÃ³ dá»¯ liá»‡u train!" });
    }

    let trainedFaces = JSON.parse(fs.readFileSync(trainedDataPath));

    trainedFaces = trainedFaces.map(person => ({
      label: person.label,
      descriptors: person.descriptors.map(desc => Array.isArray(desc) ? desc : Object.values(desc)) // ðŸŸ¢ Chuáº©n hÃ³a dá»¯ liá»‡u cÅ©
    }));

    let bestMatch = { label: "KhÃ´ng xÃ¡c Ä‘á»‹nh", distance: Infinity };

    trainedFaces.forEach((person) => {
      if (!person.descriptors || !Array.isArray(person.descriptors) || person.descriptors.length === 0) {
        console.log(`âš ï¸ KhÃ´ng cÃ³ descriptors cho: ${person.label}`);
        return;
      }

      person.descriptors.forEach((desc) => {
        const distance = faceapi.euclideanDistance(uploadedDescriptor, desc);
        if (distance < bestMatch.distance) {
          bestMatch = { label: person.label, distance };
        }
      });
    });

    // ðŸŸ¢ **NgÆ°á»¡ng nháº­n diá»‡n**
    if (bestMatch.distance < 0.5) {
      res.json({ message: `âœ… Nháº­n diá»‡n thÃ nh cÃ´ng!`, name: bestMatch.label, distance: bestMatch.distance });
    } else {
      res.json({ message: "âŒ KhÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c khuÃ´n máº·t!", name: "KhÃ´ng xÃ¡c Ä‘á»‹nh", distance: bestMatch.distance });
    }

    fs.unlinkSync(imgPath); // ðŸŸ¢ XÃ³a áº£nh sau khi xá»­ lÃ½

  } catch (error) {
    console.error("âŒ Lá»—i server:", error);
    res.status(500).json({ message: "âŒ Lá»—i server", error });
  }
};
